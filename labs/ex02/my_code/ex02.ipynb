{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(e):\n",
    "    \"\"\"Calculate the Mean Squared Error (MSE) for vector e.\"\"\"\n",
    "    return 1/2 * np.mean(e**2)\n",
    "\n",
    "def calculate_mae(e):\n",
    "    \"\"\"Calculate the Mean Absolute Error (MAE) for vector e.\"\"\"\n",
    "    return np.mean(np.abs(e))\n",
    "\n",
    "def compute_loss(y, tx, w, loss_type='mse'):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "        loss_type: 'mse' or 'mae' to specify which loss to calculate.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # Calculate the error\n",
    "    e = y - tx.dot(w)\n",
    "\n",
    "    # Return MSE or MAE based on the selected loss type\n",
    "    if loss_type == 'mse':\n",
    "        return calculate_mse(e)\n",
    "    elif loss_type == 'mae':\n",
    "        return calculate_mae(e)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid loss_type. Choose 'mse' or 'mae'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "    # Initialize a matrix to store the losses for each combination of w0 and w1\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    \n",
    "    # Iterate over all combinations of w0 and w1\n",
    "    for ind_row, w0 in enumerate(grid_w0):\n",
    "        for ind_col, w1 in enumerate(grid_w1):\n",
    "            # Form the weight vector w = [w0, w1]\n",
    "            w = np.array([w0, w1])\n",
    "            \n",
    "            # Compute the loss for this combination of weights\n",
    "            loss = compute_loss(y, tx, w)\n",
    "            \n",
    "            # Store the computed loss in the losses matrix\n",
    "            losses[ind_row, ind_col] = loss\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.42448314678248, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.071 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # Compute the error (residuals)\n",
    "    err = y - tx.dot(w)\n",
    "    \n",
    "    # Compute the gradient\n",
    "    grad = -tx.T.dot(err) / len(err)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute the gradient and the loss\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # Update w by taking a step in the direction of the negative gradient\n",
    "        w = w - gamma * grad\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.30574540147362, w1=9.435798704492294\n",
      "GD iter. 1/49: loss=265.3024621089602, w0=66.69746902191571, w1=12.266538315840004\n",
      "GD iter. 2/49: loss=37.87837955044127, w0=71.31498610804834, w1=13.115760199244331\n",
      "GD iter. 3/49: loss=17.41021212017447, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450455, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543453, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613667, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.38588786883575, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.38588786882945, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.3858878688294, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.3858878688294, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.3858878688294, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.3858878688294, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.3858878688294, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.017 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925d9daac2314e678f49788dab997a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the error for the mini-batch\n",
    "    err = y - tx.dot(w)\n",
    "    \n",
    "    # Compute the stochastic gradient\n",
    "    stoch_grad = -tx.T.dot(err) / len(err)\n",
    "    \n",
    "    return stoch_grad\n",
    "\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # Create a random mini-batch of data\n",
    "        for mini_y, mini_tx in batch_iter(y, tx, batch_size):\n",
    "            # Compute the stochastic gradient for the mini-batch\n",
    "            stoch_grad = compute_stoch_gradient(mini_y, mini_tx, w)\n",
    "            \n",
    "            # Update w using the stochastic gradient\n",
    "            w = w - gamma * stoch_grad\n",
    "            \n",
    "            # Compute the loss for this mini-batch\n",
    "            loss = compute_loss(y, tx, w)\n",
    "            \n",
    "            # Store updated weights and loss\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "            print(\n",
    "                \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2246.0904928054647, w0=7.466272606321732, w1=2.1602696528074983\n",
      "SGD iter. 1/49: loss=2055.4650498354204, w0=13.008874066808815, w1=-7.635952825006994\n",
      "SGD iter. 2/49: loss=1711.643474710837, w0=18.743763828114062, w1=-6.935855567801538\n",
      "SGD iter. 3/49: loss=1433.0042318668268, w0=23.60375620172444, w1=-5.654657445586283\n",
      "SGD iter. 4/49: loss=951.8277056110661, w0=31.182161194111444, w1=3.5055840452601394\n",
      "SGD iter. 5/49: loss=732.4881614522252, w0=36.63346029726827, w1=3.9815497308141925\n",
      "SGD iter. 6/49: loss=610.1309926198907, w0=40.65035403601637, w1=2.349228171244593\n",
      "SGD iter. 7/49: loss=549.3391896206826, w0=43.07246304455542, w1=1.047093162251625\n",
      "SGD iter. 8/49: loss=403.0737625967145, w0=47.3580268833281, w1=3.3453602680488475\n",
      "SGD iter. 9/49: loss=389.8785896163004, w0=48.20851433202308, w1=2.5386098616316395\n",
      "SGD iter. 10/49: loss=281.59458528321943, w0=51.4268535200903, w1=6.1143400186307675\n",
      "SGD iter. 11/49: loss=256.42871382969884, w0=53.890042105057496, w1=3.204738135133712\n",
      "SGD iter. 12/49: loss=218.70048174402575, w0=56.42880914784651, w1=2.42543018042762\n",
      "SGD iter. 13/49: loss=222.60658908733487, w0=55.73058333109489, w1=3.1855132352258373\n",
      "SGD iter. 14/49: loss=125.19172334619421, w0=59.37715716580626, w1=8.38703853556417\n",
      "SGD iter. 15/49: loss=85.55270049263902, w0=61.50179894905607, w1=12.348580634814237\n",
      "SGD iter. 16/49: loss=70.5277747708523, w0=62.80275028536332, w1=13.01164212629473\n",
      "SGD iter. 17/49: loss=68.50319876465723, w0=62.98691801761931, w1=13.496761055105264\n",
      "SGD iter. 18/49: loss=56.55113640294629, w0=64.44722022664105, w1=15.496235374167618\n",
      "SGD iter. 19/49: loss=51.2564430720163, w0=65.39571702582239, w1=16.53903728844862\n",
      "SGD iter. 20/49: loss=48.69872626536907, w0=65.84788066871576, w1=16.823683914313513\n",
      "SGD iter. 21/49: loss=46.96595265352187, w0=66.72221113398275, w1=17.94880024294117\n",
      "SGD iter. 22/49: loss=44.70058925642534, w0=67.01826447400984, w1=17.866684667093097\n",
      "SGD iter. 23/49: loss=42.47328459481734, w0=67.40951974333284, w1=17.90109270690987\n",
      "SGD iter. 24/49: loss=34.89542225713267, w0=68.6906115178257, w1=17.702105282880993\n",
      "SGD iter. 25/49: loss=34.960480249721016, w0=68.72942961562984, w1=17.75926778754517\n",
      "SGD iter. 26/49: loss=35.29807854228986, w0=68.82776557563945, w1=17.938168235068222\n",
      "SGD iter. 27/49: loss=31.938377450342855, w0=70.09403088717661, w1=18.261519208127005\n",
      "SGD iter. 28/49: loss=32.14186836733924, w0=70.23793695700361, w1=18.396308452675996\n",
      "SGD iter. 29/49: loss=32.468737575759924, w0=70.33288841107647, w1=18.51935324427899\n",
      "SGD iter. 30/49: loss=32.07967982225501, w0=70.42379643117279, w1=18.49468632464502\n",
      "SGD iter. 31/49: loss=32.35837082883229, w0=69.72970302785286, w1=18.08854189848468\n",
      "SGD iter. 32/49: loss=29.70665954079391, w0=69.18035264722518, w1=16.903174207306805\n",
      "SGD iter. 33/49: loss=23.359754278538215, w0=70.13157469051848, w1=15.91841953103767\n",
      "SGD iter. 34/49: loss=26.9111757093794, w0=69.57016145957633, w1=16.510254152736078\n",
      "SGD iter. 35/49: loss=24.21452626707146, w0=70.15589069458044, w1=16.274356653754396\n",
      "SGD iter. 36/49: loss=22.581975830676686, w0=71.14106685201332, w1=16.60339465736979\n",
      "SGD iter. 37/49: loss=22.29828168992559, w0=71.33691823297694, w1=16.641187389786285\n",
      "SGD iter. 38/49: loss=15.725059110878696, w0=72.6682698187423, w1=14.015344612468937\n",
      "SGD iter. 39/49: loss=16.062055267461414, w0=72.1899326909138, w1=13.114277901810802\n",
      "SGD iter. 40/49: loss=15.490534426598467, w0=73.35271156822444, w1=13.026019915264904\n",
      "SGD iter. 41/49: loss=15.407949520515823, w0=73.0899803356761, w1=13.53002247441426\n",
      "SGD iter. 42/49: loss=15.531478449513116, w0=73.56818010310697, w1=13.944431334327493\n",
      "SGD iter. 43/49: loss=15.51167859695639, w0=73.68493373541047, w1=13.793864119166585\n",
      "SGD iter. 44/49: loss=15.48406564881237, w0=73.62989776328098, w1=13.768634306553475\n",
      "SGD iter. 45/49: loss=15.41397475802525, w0=73.24171291878726, w1=13.248524221598315\n",
      "SGD iter. 46/49: loss=15.825557618595578, w0=74.22623874889392, w1=13.379089459532974\n",
      "SGD iter. 47/49: loss=16.253707185722632, w0=74.5975634950015, w1=13.669863668972829\n",
      "SGD iter. 48/49: loss=16.113570836106746, w0=74.49225883497043, w1=13.618833855170132\n",
      "SGD iter. 49/49: loss=15.595949754793697, w0=73.78222929924664, w1=13.05347335244616\n",
      "SGD: execution time=0.016 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3631d984fe3949b1912ef73860bf5bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# Reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=False)  # Subsample data without outliers\n",
    "\n",
    "height_with_outliers, weight_with_outliers, gender_with_outliers = load_data(sub_sample=True, add_outlier=True)  # Subsample data with outliers\n",
    "\n",
    "# Standardize the features and build the model data\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)\n",
    "\n",
    "x_outliers, mean_x_outliers, std_x_outliers = standardize(height_with_outliers)\n",
    "y_outliers, tx_outliers = build_model_data(x_outliers, weight_with_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2829.2722244384163, w0=51.54259072181176, w1=10.132993413506084\n",
      "GD iter. 1/49: loss=267.0500258779429, w0=67.0053679383553, w1=13.172891437557825\n",
      "GD iter. 2/49: loss=36.45002800750046, w0=71.64420110331838, w1=14.084860844773322\n",
      "GD iter. 3/49: loss=15.696028199160635, w0=73.03585105280729, w1=14.358451666937965\n",
      "GD iter. 4/49: loss=13.828168216410077, w0=73.45334603765397, w1=14.440528913587356\n",
      "GD iter. 5/49: loss=13.660060817962522, w0=73.57859453310797, w1=14.46515208758217\n",
      "GD iter. 6/49: loss=13.644931152102242, w0=73.61616908174418, w1=14.472539039780616\n",
      "GD iter. 7/49: loss=13.643569482174817, w0=73.62744144633503, w1=14.474755125440149\n",
      "GD iter. 8/49: loss=13.643446931881353, w0=73.63082315571229, w1=14.47541995113801\n",
      "GD iter. 9/49: loss=13.643435902354941, w0=73.63183766852546, w1=14.475619398847368\n",
      "GD iter. 10/49: loss=13.64343490969756, w0=73.63214202236942, w1=14.475679233160175\n",
      "GD iter. 11/49: loss=13.643434820358397, w0=73.6322333285226, w1=14.475697183454017\n",
      "GD iter. 12/49: loss=13.643434812317876, w0=73.63226072036856, w1=14.47570256854217\n",
      "GD iter. 13/49: loss=13.64343481159423, w0=73.63226893792235, w1=14.475704184068615\n",
      "GD iter. 14/49: loss=13.643434811529096, w0=73.63227140318848, w1=14.475704668726548\n",
      "GD iter. 15/49: loss=13.643434811523234, w0=73.63227214276833, w1=14.47570481412393\n",
      "GD iter. 16/49: loss=13.643434811522706, w0=73.63227236464228, w1=14.475704857743143\n",
      "GD iter. 17/49: loss=13.64343481152266, w0=73.63227243120446, w1=14.475704870828908\n",
      "GD iter. 18/49: loss=13.643434811522656, w0=73.63227245117312, w1=14.475704874754637\n",
      "GD iter. 19/49: loss=13.643434811522656, w0=73.63227245716372, w1=14.475704875932356\n",
      "GD iter. 20/49: loss=13.643434811522653, w0=73.6322724589609, w1=14.475704876285672\n",
      "GD iter. 21/49: loss=13.643434811522656, w0=73.63227245950004, w1=14.475704876391665\n",
      "GD iter. 22/49: loss=13.643434811522656, w0=73.63227245966179, w1=14.475704876423464\n",
      "GD iter. 23/49: loss=13.643434811522654, w0=73.63227245971032, w1=14.475704876433003\n",
      "GD iter. 24/49: loss=13.643434811522656, w0=73.63227245972487, w1=14.475704876435865\n",
      "GD iter. 25/49: loss=13.643434811522656, w0=73.63227245972924, w1=14.475704876436724\n",
      "GD iter. 26/49: loss=13.643434811522654, w0=73.63227245973054, w1=14.475704876436982\n",
      "GD iter. 27/49: loss=13.643434811522654, w0=73.63227245973094, w1=14.47570487643706\n",
      "GD iter. 28/49: loss=13.643434811522656, w0=73.63227245973106, w1=14.475704876437083\n",
      "GD iter. 29/49: loss=13.643434811522656, w0=73.6322724597311, w1=14.475704876437089\n",
      "GD iter. 30/49: loss=13.643434811522656, w0=73.63227245973111, w1=14.47570487643709\n",
      "GD iter. 31/49: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 32/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 33/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 34/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 35/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 36/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 37/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 38/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 39/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 40/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 41/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 42/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 43/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 44/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 45/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 46/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 47/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 48/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD iter. 49/49: loss=13.643434811522654, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD without outliers: execution time=0.003 seconds\n",
      "GD iter. 0/49: loss=2869.8351145358524, w0=51.84746409844842, w1=7.7244264061924195\n",
      "GD iter. 1/49: loss=318.2821247015965, w0=67.40170332798297, w1=10.041754328050114\n",
      "GD iter. 2/49: loss=88.6423556165128, w0=72.06797509684336, w1=10.736952704607411\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631798\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.032481534481914\n",
      "GD iter. 7/49: loss=65.93086421248087, w0=74.06294626618423, w1=11.034170866536945\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003895\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225755, w1=11.034889001593541\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670431\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608874, w1=11.034894818487496\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927507, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706557\n",
      "GD iter. 19/49: loss=65.93073010260336, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260336, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260336, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260336, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=65.93073010260336, w0=74.06780585492581, w1=11.034894865989015\n",
      "GD iter. 27/49: loss=65.93073010260336, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989099\n",
      "GD iter. 29/49: loss=65.93073010260339, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD with outliers: execution time=0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define parameters for gradient descent\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialize weights\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Fit the model on subsampled data (without outliers)\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(f\"GD without outliers: execution time={execution_time:.3f} seconds\")\n",
    "\n",
    "# Fit the model on subsampled data with outliers\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses_outliers, gd_ws_outliers = gradient_descent(y_outliers, tx_outliers, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time_outliers = (end_time - start_time).total_seconds()\n",
    "print(f\"GD with outliers: execution time={execution_time_outliers:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160ca29dacfd42bf87d2f47026f0a51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # Compute the error\n",
    "    e = y - tx.dot(w)\n",
    "    \n",
    "    # Compute the subgradient\n",
    "    subgrad = -tx.T.dot(np.sign(e)) / len(y)\n",
    "    \n",
    "    return subgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute the subgradient and the MAE loss\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w, loss_type='mae')\n",
    "        \n",
    "        # Update w using the subgradient\n",
    "        w = w - gamma * subgrad\n",
    "        \n",
    "        # Store the updated weights and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=73.63227245973114, w0=0.7, w1=1.689537398874563e-15\n",
      "SubGD iter. 1/499: loss=72.93227245973114, w0=1.4, w1=3.379074797749126e-15\n",
      "SubGD iter. 2/499: loss=72.23227245973115, w0=2.0999999999999996, w1=5.068612196623689e-15\n",
      "SubGD iter. 3/499: loss=71.53227245973116, w0=2.8, w1=6.758149595498252e-15\n",
      "SubGD iter. 4/499: loss=70.83227245973114, w0=3.5, w1=8.447686994372815e-15\n",
      "SubGD iter. 5/499: loss=70.13227245973114, w0=4.2, w1=1.0137224393247379e-14\n",
      "SubGD iter. 6/499: loss=69.43227245973115, w0=4.9, w1=1.1826761792121942e-14\n",
      "SubGD iter. 7/499: loss=68.73227245973115, w0=5.6000000000000005, w1=1.3516299190996506e-14\n",
      "SubGD iter. 8/499: loss=68.03227245973115, w0=6.300000000000001, w1=1.5205836589871068e-14\n",
      "SubGD iter. 9/499: loss=67.33227245973114, w0=7.000000000000001, w1=1.689537398874563e-14\n",
      "SubGD iter. 10/499: loss=66.63227245973115, w0=7.700000000000001, w1=1.8584911387620192e-14\n",
      "SubGD iter. 11/499: loss=65.93227245973114, w0=8.4, w1=2.0274448786494754e-14\n",
      "SubGD iter. 12/499: loss=65.23227245973113, w0=9.1, w1=2.1963986185369316e-14\n",
      "SubGD iter. 13/499: loss=64.53227245973115, w0=9.799999999999999, w1=2.3653523584243878e-14\n",
      "SubGD iter. 14/499: loss=63.83227245973116, w0=10.499999999999998, w1=2.534306098311844e-14\n",
      "SubGD iter. 15/499: loss=63.13227245973115, w0=11.199999999999998, w1=2.7032598381993002e-14\n",
      "SubGD iter. 16/499: loss=62.432272459731145, w0=11.899999999999997, w1=2.8722135780867564e-14\n",
      "SubGD iter. 17/499: loss=61.732272459731156, w0=12.599999999999996, w1=3.041167317974213e-14\n",
      "SubGD iter. 18/499: loss=61.03227245973116, w0=13.299999999999995, w1=3.2101210578616694e-14\n",
      "SubGD iter. 19/499: loss=60.33227245973116, w0=13.999999999999995, w1=3.379074797749126e-14\n",
      "SubGD iter. 20/499: loss=59.632272459731155, w0=14.699999999999994, w1=3.5480285376365825e-14\n",
      "SubGD iter. 21/499: loss=58.93227245973116, w0=15.399999999999993, w1=3.716982277524039e-14\n",
      "SubGD iter. 22/499: loss=58.232272459731156, w0=16.099999999999994, w1=3.8859360174114955e-14\n",
      "SubGD iter. 23/499: loss=57.53227245973116, w0=16.799999999999994, w1=4.054889757298952e-14\n",
      "SubGD iter. 24/499: loss=56.83227245973116, w0=17.499999999999993, w1=4.2238434971864086e-14\n",
      "SubGD iter. 25/499: loss=56.132272459731155, w0=18.199999999999992, w1=4.392797237073865e-14\n",
      "SubGD iter. 26/499: loss=55.43227245973116, w0=18.89999999999999, w1=4.5617509769613216e-14\n",
      "SubGD iter. 27/499: loss=54.732272459731156, w0=19.59999999999999, w1=4.730704716848778e-14\n",
      "SubGD iter. 28/499: loss=54.03227245973116, w0=20.29999999999999, w1=4.8996584567362346e-14\n",
      "SubGD iter. 29/499: loss=53.33227245973116, w0=20.99999999999999, w1=5.068612196623691e-14\n",
      "SubGD iter. 30/499: loss=52.632272459731155, w0=21.69999999999999, w1=5.2375659365111477e-14\n",
      "SubGD iter. 31/499: loss=51.93227245973116, w0=22.399999999999988, w1=5.406519676398604e-14\n",
      "SubGD iter. 32/499: loss=51.232272459731156, w0=23.099999999999987, w1=5.575473416286061e-14\n",
      "SubGD iter. 33/499: loss=50.532272459731175, w0=23.799999999999986, w1=5.744427156173517e-14\n",
      "SubGD iter. 34/499: loss=49.832272459731165, w0=24.499999999999986, w1=5.913380896060972e-14\n",
      "SubGD iter. 35/499: loss=49.13227245973117, w0=25.199999999999985, w1=6.082334635948428e-14\n",
      "SubGD iter. 36/499: loss=48.432272459731166, w0=25.899999999999984, w1=6.251288375835884e-14\n",
      "SubGD iter. 37/499: loss=47.73227245973116, w0=26.599999999999984, w1=6.42024211572334e-14\n",
      "SubGD iter. 38/499: loss=47.03227245973117, w0=27.299999999999983, w1=6.589195855610796e-14\n",
      "SubGD iter. 39/499: loss=46.332272459731165, w0=27.999999999999982, w1=6.758149595498252e-14\n",
      "SubGD iter. 40/499: loss=45.63227245973117, w0=28.69999999999998, w1=6.927103335385708e-14\n",
      "SubGD iter. 41/499: loss=44.93227245973117, w0=29.39999999999998, w1=7.096057075273164e-14\n",
      "SubGD iter. 42/499: loss=44.23227245973118, w0=30.09999999999998, w1=7.26501081516062e-14\n",
      "SubGD iter. 43/499: loss=43.53227245973117, w0=30.79999999999998, w1=7.433964555048075e-14\n",
      "SubGD iter. 44/499: loss=42.832272459731165, w0=31.49999999999998, w1=7.602918294935531e-14\n",
      "SubGD iter. 45/499: loss=42.132272459731176, w0=32.19999999999998, w1=7.771872034822987e-14\n",
      "SubGD iter. 46/499: loss=41.432272459731166, w0=32.899999999999984, w1=7.940825774710443e-14\n",
      "SubGD iter. 47/499: loss=40.73227245973116, w0=33.59999999999999, w1=8.109779514597899e-14\n",
      "SubGD iter. 48/499: loss=40.03227245973117, w0=34.29999999999999, w1=8.278733254485355e-14\n",
      "SubGD iter. 49/499: loss=39.33227245973116, w0=34.99999999999999, w1=8.447686994372811e-14\n",
      "SubGD iter. 50/499: loss=38.632272459731155, w0=35.699999999999996, w1=8.616640734260267e-14\n",
      "SubGD iter. 51/499: loss=37.93227245973115, w0=36.4, w1=8.785594474147723e-14\n",
      "SubGD iter. 52/499: loss=37.23227245973115, w0=37.1, w1=8.954548214035178e-14\n",
      "SubGD iter. 53/499: loss=36.532272459731146, w0=37.800000000000004, w1=9.123501953922634e-14\n",
      "SubGD iter. 54/499: loss=35.83227245973115, w0=38.50000000000001, w1=9.29245569381009e-14\n",
      "SubGD iter. 55/499: loss=35.13227245973114, w0=39.20000000000001, w1=9.461409433697546e-14\n",
      "SubGD iter. 56/499: loss=34.43227245973114, w0=39.90000000000001, w1=9.630363173585002e-14\n",
      "SubGD iter. 57/499: loss=33.73227245973114, w0=40.600000000000016, w1=9.799316913472458e-14\n",
      "SubGD iter. 58/499: loss=33.03227245973113, w0=41.30000000000002, w1=9.968270653359914e-14\n",
      "SubGD iter. 59/499: loss=32.33227245973113, w0=42.00000000000002, w1=1.013722439324737e-13\n",
      "SubGD iter. 60/499: loss=31.632272459731126, w0=42.700000000000024, w1=1.0306178133134826e-13\n",
      "SubGD iter. 61/499: loss=30.932272459731124, w0=43.40000000000003, w1=1.0475131873022281e-13\n",
      "SubGD iter. 62/499: loss=30.23227245973112, w0=44.10000000000003, w1=1.0644085612909737e-13\n",
      "SubGD iter. 63/499: loss=29.53227245973112, w0=44.80000000000003, w1=1.0813039352797193e-13\n",
      "SubGD iter. 64/499: loss=28.83227245973111, w0=45.500000000000036, w1=1.0981993092684649e-13\n",
      "SubGD iter. 65/499: loss=28.132272459731112, w0=46.20000000000004, w1=1.1150946832572105e-13\n",
      "SubGD iter. 66/499: loss=27.432272459731113, w0=46.90000000000004, w1=1.1319900572459561e-13\n",
      "SubGD iter. 67/499: loss=26.73779145802111, w0=47.59300000000004, w1=0.012822729222841382\n",
      "SubGD iter. 68/499: loss=26.05503366547825, w0=48.27900000000004, w1=0.038067565076886134\n",
      "SubGD iter. 69/499: loss=25.38184323442497, w0=48.96500000000004, w1=0.06331240093093088\n",
      "SubGD iter. 70/499: loss=24.719105125582008, w0=49.63000000000004, w1=0.12140253076845675\n",
      "SubGD iter. 71/499: loss=24.087121006068195, w0=50.28800000000004, w1=0.19295915708008177\n",
      "SubGD iter. 72/499: loss=23.46128621925519, w0=50.94600000000004, w1=0.2645157833917068\n",
      "SubGD iter. 73/499: loss=22.84325714862478, w0=51.59000000000004, w1=0.36003710381024834\n",
      "SubGD iter. 74/499: loss=22.241121962518005, w0=52.22000000000004, w1=0.47488016550951173\n",
      "SubGD iter. 75/499: loss=21.655286054944355, w0=52.84300000000004, w1=0.6005235649987757\n",
      "SubGD iter. 76/499: loss=21.0793958327291, w0=53.45900000000004, w1=0.735466325292315\n",
      "SubGD iter. 77/499: loss=20.514845885811628, w0=54.06800000000004, w1=0.8798253451603716\n",
      "SubGD iter. 78/499: loss=19.961125317625953, w0=54.66300000000004, w1=1.0417652853159167\n",
      "SubGD iter. 79/499: loss=19.41791168302941, w0=55.25800000000004, w1=1.2037052254714617\n",
      "SubGD iter. 80/499: loss=18.878236910794513, w0=55.83900000000004, w1=1.3822638190738608\n",
      "SubGD iter. 81/499: loss=18.353456597562687, w0=56.41300000000004, w1=1.5664626351241284\n",
      "SubGD iter. 82/499: loss=17.844052339896574, w0=56.95200000000004, w1=1.7871599649710128\n",
      "SubGD iter. 83/499: loss=17.361716193576623, w0=57.48400000000004, w1=2.013835121218472\n",
      "SubGD iter. 84/499: loss=16.88399387006261, w0=58.016000000000034, w1=2.240510277465931\n",
      "SubGD iter. 85/499: loss=16.413613502650648, w0=58.513000000000034, w1=2.4977608864129537\n",
      "SubGD iter. 86/499: loss=15.966203680074054, w0=59.01000000000003, w1=2.7550114953599762\n",
      "SubGD iter. 87/499: loss=15.523106852131724, w0=59.49300000000003, w1=3.019114299724235\n",
      "SubGD iter. 88/499: loss=15.090193578884488, w0=59.97600000000003, w1=3.2832171040884934\n",
      "SubGD iter. 89/499: loss=14.66058524198747, w0=60.45200000000003, w1=3.5478129339056244\n",
      "SubGD iter. 90/499: loss=14.23973303083728, w0=60.89300000000003, w1=3.842709112855987\n",
      "SubGD iter. 91/499: loss=13.840267444700885, w0=61.32000000000003, w1=4.148442254175186\n",
      "SubGD iter. 92/499: loss=13.446896701260966, w0=61.74000000000003, w1=4.458787226613845\n",
      "SubGD iter. 93/499: loss=13.057305269949607, w0=62.16000000000003, w1=4.769132199052504\n",
      "SubGD iter. 94/499: loss=12.667713838638242, w0=62.580000000000034, w1=5.079477171491163\n",
      "SubGD iter. 95/499: loss=12.282719899061476, w0=62.979000000000035, w1=5.401328404320427\n",
      "SubGD iter. 96/499: loss=11.909740029963835, w0=63.37100000000004, w1=5.725928703251706\n",
      "SubGD iter. 97/499: loss=11.5404382465704, w0=63.74900000000004, w1=6.061744039727748\n",
      "SubGD iter. 98/499: loss=11.17549210313398, w0=64.12000000000003, w1=6.401747716728324\n",
      "SubGD iter. 99/499: loss=10.813715674028394, w0=64.49100000000003, w1=6.7417513937289\n",
      "SubGD iter. 100/499: loss=10.453187772903034, w0=64.87600000000003, w1=7.061378131166487\n",
      "SubGD iter. 101/499: loss=10.097922537835116, w0=65.24700000000003, w1=7.387523593880775\n",
      "SubGD iter. 102/499: loss=9.749334162336382, w0=65.61800000000002, w1=7.713669056595062\n",
      "SubGD iter. 103/499: loss=9.401241735074212, w0=65.98200000000003, w1=8.040435506798637\n",
      "SubGD iter. 104/499: loss=9.060649420920207, w0=66.34600000000003, w1=8.353859837656561\n",
      "SubGD iter. 105/499: loss=8.732003274275774, w0=66.71700000000003, w1=8.65351368365696\n",
      "SubGD iter. 106/499: loss=8.409580241948017, w0=67.08100000000003, w1=8.955524223771478\n",
      "SubGD iter. 107/499: loss=8.090702266252839, w0=67.43800000000003, w1=9.254985017110517\n",
      "SubGD iter. 108/499: loss=7.7813257619322505, w0=67.78100000000003, w1=9.560846653934009\n",
      "SubGD iter. 109/499: loss=7.483796127626859, w0=68.11700000000003, w1=9.860337267127171\n",
      "SubGD iter. 110/499: loss=7.199800715077393, w0=68.43200000000003, w1=10.156521139455217\n",
      "SubGD iter. 111/499: loss=6.933263878966207, w0=68.74700000000003, w1=10.4444534773485\n",
      "SubGD iter. 112/499: loss=6.678120641163087, w0=69.03400000000003, w1=10.743406876764555\n",
      "SubGD iter. 113/499: loss=6.435162436532354, w0=69.31400000000004, w1=11.038005391074643\n",
      "SubGD iter. 114/499: loss=6.20459881064318, w0=69.59400000000004, w1=11.313287847901137\n",
      "SubGD iter. 115/499: loss=5.989123159786052, w0=69.86700000000003, w1=11.578413278202857\n",
      "SubGD iter. 116/499: loss=5.782236740082235, w0=70.14000000000003, w1=11.843538708504578\n",
      "SubGD iter. 117/499: loss=5.577597038947097, w0=70.39900000000003, w1=12.104101240231266\n",
      "SubGD iter. 118/499: loss=5.385762150889767, w0=70.65100000000002, w1=12.36722983468919\n",
      "SubGD iter. 119/499: loss=5.197727884829008, w0=70.90300000000002, w1=12.607410619209137\n",
      "SubGD iter. 120/499: loss=5.028649085704107, w0=71.14800000000002, w1=12.829819894660064\n",
      "SubGD iter. 121/499: loss=4.875070641712608, w0=71.37900000000002, w1=13.051299546685483\n",
      "SubGD iter. 122/499: loss=4.735029755881435, w0=71.59600000000002, w1=13.253978279130138\n",
      "SubGD iter. 123/499: loss=4.614755982745981, w0=71.80600000000001, w1=13.44375255576235\n",
      "SubGD iter. 124/499: loss=4.5072128081487435, w0=71.98100000000001, w1=13.60001256733914\n",
      "SubGD iter. 125/499: loss=4.441175630507938, w0=72.12100000000001, w1=13.709638751573966\n",
      "SubGD iter. 126/499: loss=4.396127196294587, w0=72.254, w1=13.823710297553676\n",
      "SubGD iter. 127/499: loss=4.357285449419879, w0=72.35900000000001, w1=13.928950177753503\n",
      "SubGD iter. 128/499: loss=4.326375625963027, w0=72.45700000000001, w1=14.033063640618654\n",
      "SubGD iter. 129/499: loss=4.3004298027686385, w0=72.534, w1=14.118590076651586\n",
      "SubGD iter. 130/499: loss=4.28151012953936, w0=72.611, w1=14.204116512684518\n",
      "SubGD iter. 131/499: loss=4.264744476142134, w0=72.667, w1=14.26236232246874\n",
      "SubGD iter. 132/499: loss=4.255554279982528, w0=72.71600000000001, w1=14.312508189781902\n",
      "SubGD iter. 133/499: loss=4.2485319828274, w0=72.76500000000001, w1=14.362654057095064\n",
      "SubGD iter. 134/499: loss=4.2415096856722725, w0=72.81400000000002, w1=14.412799924408226\n",
      "SubGD iter. 135/499: loss=4.234487388517144, w0=72.86300000000003, w1=14.462945791721388\n",
      "SubGD iter. 136/499: loss=4.2276479512381435, w0=72.91900000000003, w1=14.500669552403235\n",
      "SubGD iter. 137/499: loss=4.221939526801602, w0=72.96100000000003, w1=14.528246426173618\n",
      "SubGD iter. 138/499: loss=4.218335222850053, w0=73.01000000000003, w1=14.543000570721277\n",
      "SubGD iter. 139/499: loss=4.214964414103767, w0=73.04500000000003, w1=14.568377913364856\n",
      "SubGD iter. 140/499: loss=4.212817061139228, w0=73.07300000000004, w1=14.586058146365032\n",
      "SubGD iter. 141/499: loss=4.211250503083599, w0=73.10100000000004, w1=14.603738379365208\n",
      "SubGD iter. 142/499: loss=4.20968394502797, w0=73.12900000000005, w1=14.621418612365384\n",
      "SubGD iter. 143/499: loss=4.2081462339944675, w0=73.16400000000004, w1=14.626276116142835\n",
      "SubGD iter. 144/499: loss=4.206981534135997, w0=73.18500000000004, w1=14.637490968842995\n",
      "SubGD iter. 145/499: loss=4.206171858534444, w0=73.20600000000005, w1=14.648705821543155\n",
      "SubGD iter. 146/499: loss=4.205362182932893, w0=73.22700000000005, w1=14.659920674243315\n",
      "SubGD iter. 147/499: loss=4.204552507331341, w0=73.24800000000005, w1=14.671135526943475\n",
      "SubGD iter. 148/499: loss=4.203742831729789, w0=73.26900000000005, w1=14.682350379643635\n",
      "SubGD iter. 149/499: loss=4.202933156128238, w0=73.29000000000005, w1=14.693565232343795\n",
      "SubGD iter. 150/499: loss=4.202167194169124, w0=73.30400000000004, w1=14.703897822273019\n",
      "SubGD iter. 151/499: loss=4.201937252423053, w0=73.30400000000004, w1=14.699292575283707\n",
      "SubGD iter. 152/499: loss=4.201975831785367, w0=73.30400000000004, w1=14.71264121692517\n",
      "SubGD iter. 153/499: loss=4.201994774554335, w0=73.30400000000004, w1=14.708035969935858\n",
      "SubGD iter. 154/499: loss=4.201964476983147, w0=73.30400000000004, w1=14.703430722946546\n",
      "SubGD iter. 155/499: loss=4.20193739281677, w0=73.31100000000005, w1=14.704357257956694\n",
      "SubGD iter. 156/499: loss=4.20195335946007, w0=73.30400000000004, w1=14.712174117598698\n",
      "SubGD iter. 157/499: loss=4.20199170154324, w0=73.30400000000004, w1=14.707568870609386\n",
      "SubGD iter. 158/499: loss=4.20196140397205, w0=73.30400000000004, w1=14.702963623620073\n",
      "SubGD iter. 159/499: loss=4.201938011079454, w0=73.31100000000005, w1=14.703890158630221\n",
      "SubGD iter. 160/499: loss=4.201958575531319, w0=73.30400000000004, w1=14.711707018272225\n",
      "SubGD iter. 161/499: loss=4.201988628532145, w0=73.30400000000004, w1=14.707101771282913\n",
      "SubGD iter. 162/499: loss=4.201958330960955, w0=73.30400000000004, w1=14.7024965242936\n",
      "SubGD iter. 163/499: loss=4.201938629342139, w0=73.31100000000005, w1=14.703423059303748\n",
      "SubGD iter. 164/499: loss=4.201963791602567, w0=73.30400000000004, w1=14.711239918945752\n",
      "SubGD iter. 165/499: loss=4.201985555521049, w0=73.30400000000004, w1=14.70663467195644\n",
      "SubGD iter. 166/499: loss=4.20195525794986, w0=73.30400000000004, w1=14.702029424967128\n",
      "SubGD iter. 167/499: loss=4.201939247604823, w0=73.31100000000005, w1=14.702955959977276\n",
      "SubGD iter. 168/499: loss=4.201969007673815, w0=73.30400000000004, w1=14.71077281961928\n",
      "SubGD iter. 169/499: loss=4.201982482509953, w0=73.30400000000004, w1=14.706167572629967\n",
      "SubGD iter. 170/499: loss=4.201952184938764, w0=73.30400000000004, w1=14.701562325640655\n",
      "SubGD iter. 171/499: loss=4.201939865867507, w0=73.31100000000005, w1=14.702488860650803\n",
      "SubGD iter. 172/499: loss=4.201974223745064, w0=73.30400000000004, w1=14.710305720292807\n",
      "SubGD iter. 173/499: loss=4.201979409498858, w0=73.30400000000004, w1=14.705700473303494\n",
      "SubGD iter. 174/499: loss=4.201949111927669, w0=73.30400000000004, w1=14.701095226314182\n",
      "SubGD iter. 175/499: loss=4.201941456153066, w0=73.30400000000004, w1=14.714443867955646\n",
      "SubGD iter. 176/499: loss=4.202006634058952, w0=73.30400000000004, w1=14.709838620966334\n",
      "SubGD iter. 177/499: loss=4.201976336487762, w0=73.30400000000004, w1=14.705233373977022\n",
      "SubGD iter. 178/499: loss=4.2019460389165735, w0=73.30400000000004, w1=14.70062812698771\n",
      "SubGD iter. 179/499: loss=4.201950363498095, w0=73.30400000000004, w1=14.713976768629173\n",
      "SubGD iter. 180/499: loss=4.202003561047856, w0=73.30400000000004, w1=14.709371521639861\n",
      "SubGD iter. 181/499: loss=4.201973263476667, w0=73.30400000000004, w1=14.704766274650549\n",
      "SubGD iter. 182/499: loss=4.201942965905476, w0=73.30400000000004, w1=14.700161027661236\n",
      "SubGD iter. 183/499: loss=4.201959270843123, w0=73.30400000000004, w1=14.7135096693027\n",
      "SubGD iter. 184/499: loss=4.202000488036759, w0=73.30400000000004, w1=14.708904422313388\n",
      "SubGD iter. 185/499: loss=4.201970190465571, w0=73.30400000000004, w1=14.704299175324076\n",
      "SubGD iter. 186/499: loss=4.201939892894382, w0=73.30400000000004, w1=14.699693928334764\n",
      "SubGD iter. 187/499: loss=4.201968178188151, w0=73.30400000000004, w1=14.713042569976228\n",
      "SubGD iter. 188/499: loss=4.201997415025664, w0=73.30400000000004, w1=14.708437322986915\n",
      "SubGD iter. 189/499: loss=4.201967117454475, w0=73.30400000000004, w1=14.703832075997603\n",
      "SubGD iter. 190/499: loss=4.201936861577265, w0=73.31100000000005, w1=14.704758611007751\n",
      "SubGD iter. 191/499: loss=4.201948877573689, w0=73.30400000000004, w1=14.712575470649755\n",
      "SubGD iter. 192/499: loss=4.201994342014569, w0=73.30400000000004, w1=14.707970223660443\n",
      "SubGD iter. 193/499: loss=4.201964044443379, w0=73.30400000000004, w1=14.70336497667113\n",
      "SubGD iter. 194/499: loss=4.201937479839949, w0=73.31100000000005, w1=14.704291511681278\n",
      "SubGD iter. 195/499: loss=4.201954093644938, w0=73.30400000000004, w1=14.712108371323282\n",
      "SubGD iter. 196/499: loss=4.201991269003473, w0=73.30400000000004, w1=14.70750312433397\n",
      "SubGD iter. 197/499: loss=4.201960971432284, w0=73.30400000000004, w1=14.702897877344657\n",
      "SubGD iter. 198/499: loss=4.201938098102634, w0=73.31100000000005, w1=14.703824412354805\n",
      "SubGD iter. 199/499: loss=4.2019593097161865, w0=73.30400000000004, w1=14.71164127199681\n",
      "SubGD iter. 200/499: loss=4.201988195992378, w0=73.30400000000004, w1=14.707036025007497\n",
      "SubGD iter. 201/499: loss=4.201957898421188, w0=73.30400000000004, w1=14.702430778018185\n",
      "SubGD iter. 202/499: loss=4.201938716365319, w0=73.31100000000005, w1=14.703357313028333\n",
      "SubGD iter. 203/499: loss=4.201964525787434, w0=73.30400000000004, w1=14.711174172670336\n",
      "SubGD iter. 204/499: loss=4.201985122981282, w0=73.30400000000004, w1=14.706568925681024\n",
      "SubGD iter. 205/499: loss=4.201954825410092, w0=73.30400000000004, w1=14.701963678691712\n",
      "SubGD iter. 206/499: loss=4.201939334628004, w0=73.31100000000005, w1=14.70289021370186\n",
      "SubGD iter. 207/499: loss=4.201969741858683, w0=73.30400000000004, w1=14.710707073343864\n",
      "SubGD iter. 208/499: loss=4.201982049970186, w0=73.30400000000004, w1=14.706101826354551\n",
      "SubGD iter. 209/499: loss=4.201951752398997, w0=73.30400000000004, w1=14.701496579365239\n",
      "SubGD iter. 210/499: loss=4.201939952890688, w0=73.31100000000005, w1=14.702423114375387\n",
      "SubGD iter. 211/499: loss=4.201974957929932, w0=73.30400000000004, w1=14.71023997401739\n",
      "SubGD iter. 212/499: loss=4.20197897695909, w0=73.30400000000004, w1=14.705634727028079\n",
      "SubGD iter. 213/499: loss=4.2019486793879, w0=73.30400000000004, w1=14.701029480038766\n",
      "SubGD iter. 214/499: loss=4.20194270990088, w0=73.30400000000004, w1=14.71437812168023\n",
      "SubGD iter. 215/499: loss=4.202006201519184, w0=73.30400000000004, w1=14.709772874690918\n",
      "SubGD iter. 216/499: loss=4.201975903947995, w0=73.30400000000004, w1=14.705167627701606\n",
      "SubGD iter. 217/499: loss=4.201945606376805, w0=73.30400000000004, w1=14.700562380712293\n",
      "SubGD iter. 218/499: loss=4.201951617245909, w0=73.30400000000004, w1=14.713911022353757\n",
      "SubGD iter. 219/499: loss=4.202003128508089, w0=73.30400000000004, w1=14.709305775364445\n",
      "SubGD iter. 220/499: loss=4.201972830936899, w0=73.30400000000004, w1=14.704700528375133\n",
      "SubGD iter. 221/499: loss=4.2019425333657106, w0=73.30400000000004, w1=14.70009528138582\n",
      "SubGD iter. 222/499: loss=4.2019605245909375, w0=73.30400000000004, w1=14.713443923027285\n",
      "SubGD iter. 223/499: loss=4.202000055496994, w0=73.30400000000004, w1=14.708838676037972\n",
      "SubGD iter. 224/499: loss=4.201969757925804, w0=73.30400000000004, w1=14.70423342904866\n",
      "SubGD iter. 225/499: loss=4.201939460354615, w0=73.30400000000004, w1=14.699628182059348\n",
      "SubGD iter. 226/499: loss=4.201969431935965, w0=73.30400000000004, w1=14.712976823700812\n",
      "SubGD iter. 227/499: loss=4.201996982485897, w0=73.30400000000004, w1=14.7083715767115\n",
      "SubGD iter. 228/499: loss=4.201966684914708, w0=73.30400000000004, w1=14.703766329722187\n",
      "SubGD iter. 229/499: loss=4.201936948600445, w0=73.31100000000005, w1=14.704692864732335\n",
      "SubGD iter. 230/499: loss=4.2019496117585575, w0=73.30400000000004, w1=14.712509724374339\n",
      "SubGD iter. 231/499: loss=4.201993909474802, w0=73.30400000000004, w1=14.707904477385027\n",
      "SubGD iter. 232/499: loss=4.201963611903612, w0=73.30400000000004, w1=14.703299230395714\n",
      "SubGD iter. 233/499: loss=4.201937566863129, w0=73.31100000000005, w1=14.704225765405862\n",
      "SubGD iter. 234/499: loss=4.201954827829805, w0=73.30400000000004, w1=14.712042625047866\n",
      "SubGD iter. 235/499: loss=4.201990836463706, w0=73.30400000000004, w1=14.707437378058554\n",
      "SubGD iter. 236/499: loss=4.201960538892516, w0=73.30400000000004, w1=14.702832131069242\n",
      "SubGD iter. 237/499: loss=4.201938185125814, w0=73.31100000000005, w1=14.70375866607939\n",
      "SubGD iter. 238/499: loss=4.201960043901053, w0=73.30400000000004, w1=14.711575525721393\n",
      "SubGD iter. 239/499: loss=4.2019877634526095, w0=73.30400000000004, w1=14.706970278732081\n",
      "SubGD iter. 240/499: loss=4.201957465881422, w0=73.30400000000004, w1=14.702365031742769\n",
      "SubGD iter. 241/499: loss=4.201938803388499, w0=73.31100000000005, w1=14.703291566752917\n",
      "SubGD iter. 242/499: loss=4.201965259972302, w0=73.30400000000004, w1=14.71110842639492\n",
      "SubGD iter. 243/499: loss=4.201984690441515, w0=73.30400000000004, w1=14.706503179405608\n",
      "SubGD iter. 244/499: loss=4.201954392870325, w0=73.30400000000004, w1=14.701897932416296\n",
      "SubGD iter. 245/499: loss=4.201939421651183, w0=73.31100000000005, w1=14.702824467426444\n",
      "SubGD iter. 246/499: loss=4.201970476043551, w0=73.30400000000004, w1=14.710641327068448\n",
      "SubGD iter. 247/499: loss=4.20198161743042, w0=73.30400000000004, w1=14.706036080079135\n",
      "SubGD iter. 248/499: loss=4.20195131985923, w0=73.30400000000004, w1=14.701430833089823\n",
      "SubGD iter. 249/499: loss=4.201940039913867, w0=73.31100000000005, w1=14.702357368099971\n",
      "SubGD iter. 250/499: loss=4.201975692114798, w0=73.30400000000004, w1=14.710174227741975\n",
      "SubGD iter. 251/499: loss=4.201978544419324, w0=73.30400000000004, w1=14.705568980752663\n",
      "SubGD iter. 252/499: loss=4.201948246848134, w0=73.30400000000004, w1=14.70096373376335\n",
      "SubGD iter. 253/499: loss=4.201943963648693, w0=73.30400000000004, w1=14.714312375404814\n",
      "SubGD iter. 254/499: loss=4.202005768979418, w0=73.30400000000004, w1=14.709707128415502\n",
      "SubGD iter. 255/499: loss=4.201975471408227, w0=73.30400000000004, w1=14.70510188142619\n",
      "SubGD iter. 256/499: loss=4.201945173837038, w0=73.30400000000004, w1=14.700496634436877\n",
      "SubGD iter. 257/499: loss=4.201952870993723, w0=73.30400000000004, w1=14.713845276078342\n",
      "SubGD iter. 258/499: loss=4.202002695968321, w0=73.30400000000004, w1=14.70924002908903\n",
      "SubGD iter. 259/499: loss=4.201972398397133, w0=73.30400000000004, w1=14.704634782099717\n",
      "SubGD iter. 260/499: loss=4.201942100825943, w0=73.30400000000004, w1=14.700029535110405\n",
      "SubGD iter. 261/499: loss=4.2019617783387515, w0=73.30400000000004, w1=14.713378176751869\n",
      "SubGD iter. 262/499: loss=4.201999622957226, w0=73.30400000000004, w1=14.708772929762556\n",
      "SubGD iter. 263/499: loss=4.201969325386036, w0=73.30400000000004, w1=14.704167682773244\n",
      "SubGD iter. 264/499: loss=4.201939027814848, w0=73.30400000000004, w1=14.699562435783932\n",
      "SubGD iter. 265/499: loss=4.201970685683779, w0=73.30400000000004, w1=14.712911077425396\n",
      "SubGD iter. 266/499: loss=4.20199654994613, w0=73.30400000000004, w1=14.708305830436084\n",
      "SubGD iter. 267/499: loss=4.201966252374941, w0=73.30400000000004, w1=14.703700583446771\n",
      "SubGD iter. 268/499: loss=4.201937035623624, w0=73.31100000000005, w1=14.70462711845692\n",
      "SubGD iter. 269/499: loss=4.201950345943423, w0=73.30400000000004, w1=14.712443978098923\n",
      "SubGD iter. 270/499: loss=4.201993476935035, w0=73.30400000000004, w1=14.70783873110961\n",
      "SubGD iter. 271/499: loss=4.201963179363845, w0=73.30400000000004, w1=14.703233484120299\n",
      "SubGD iter. 272/499: loss=4.201937653886309, w0=73.31100000000005, w1=14.704160019130446\n",
      "SubGD iter. 273/499: loss=4.201955562014672, w0=73.30400000000004, w1=14.71197687877245\n",
      "SubGD iter. 274/499: loss=4.20199040392394, w0=73.30400000000004, w1=14.707371631783138\n",
      "SubGD iter. 275/499: loss=4.201960106352749, w0=73.30400000000004, w1=14.702766384793826\n",
      "SubGD iter. 276/499: loss=4.201938272148994, w0=73.31100000000005, w1=14.703692919803974\n",
      "SubGD iter. 277/499: loss=4.20196077808592, w0=73.30400000000004, w1=14.711509779445977\n",
      "SubGD iter. 278/499: loss=4.201987330912844, w0=73.30400000000004, w1=14.706904532456665\n",
      "SubGD iter. 279/499: loss=4.201957033341654, w0=73.30400000000004, w1=14.702299285467353\n",
      "SubGD iter. 280/499: loss=4.201938890411679, w0=73.31100000000005, w1=14.7032258204775\n",
      "SubGD iter. 281/499: loss=4.2019659941571685, w0=73.30400000000004, w1=14.711042680119505\n",
      "SubGD iter. 282/499: loss=4.2019842579017475, w0=73.30400000000004, w1=14.706437433130192\n",
      "SubGD iter. 283/499: loss=4.201953960330558, w0=73.30400000000004, w1=14.70183218614088\n",
      "SubGD iter. 284/499: loss=4.201939508674363, w0=73.31100000000005, w1=14.702758721151028\n",
      "SubGD iter. 285/499: loss=4.201971210228417, w0=73.30400000000004, w1=14.710575580793032\n",
      "SubGD iter. 286/499: loss=4.201981184890652, w0=73.30400000000004, w1=14.70597033380372\n",
      "SubGD iter. 287/499: loss=4.201950887319462, w0=73.30400000000004, w1=14.701365086814407\n",
      "SubGD iter. 288/499: loss=4.201940126937047, w0=73.31100000000005, w1=14.702291621824555\n",
      "SubGD iter. 289/499: loss=4.201976426299666, w0=73.30400000000004, w1=14.710108481466559\n",
      "SubGD iter. 290/499: loss=4.201978111879556, w0=73.30400000000004, w1=14.705503234477247\n",
      "SubGD iter. 291/499: loss=4.201947814308368, w0=73.30400000000004, w1=14.700897987487934\n",
      "SubGD iter. 292/499: loss=4.201945217396508, w0=73.30400000000004, w1=14.714246629129399\n",
      "SubGD iter. 293/499: loss=4.20200533643965, w0=73.30400000000004, w1=14.709641382140086\n",
      "SubGD iter. 294/499: loss=4.201975038868461, w0=73.30400000000004, w1=14.705036135150774\n",
      "SubGD iter. 295/499: loss=4.201944741297271, w0=73.30400000000004, w1=14.700430888161462\n",
      "SubGD iter. 296/499: loss=4.201954124741536, w0=73.30400000000004, w1=14.713779529802926\n",
      "SubGD iter. 297/499: loss=4.202002263428555, w0=73.30400000000004, w1=14.709174282813613\n",
      "SubGD iter. 298/499: loss=4.201971965857365, w0=73.30400000000004, w1=14.704569035824301\n",
      "SubGD iter. 299/499: loss=4.201941668286176, w0=73.30400000000004, w1=14.699963788834989\n",
      "SubGD iter. 300/499: loss=4.2019630320865655, w0=73.30400000000004, w1=14.713312430476453\n",
      "SubGD iter. 301/499: loss=4.201999190417459, w0=73.30400000000004, w1=14.70870718348714\n",
      "SubGD iter. 302/499: loss=4.20196889284627, w0=73.30400000000004, w1=14.704101936497828\n",
      "SubGD iter. 303/499: loss=4.20193859527508, w0=73.30400000000004, w1=14.699496689508516\n",
      "SubGD iter. 304/499: loss=4.201971939431594, w0=73.30400000000004, w1=14.71284533114998\n",
      "SubGD iter. 305/499: loss=4.201996117406363, w0=73.30400000000004, w1=14.708240084160668\n",
      "SubGD iter. 306/499: loss=4.2019658198351735, w0=73.30400000000004, w1=14.703634837171355\n",
      "SubGD iter. 307/499: loss=4.201937122646806, w0=73.31100000000005, w1=14.704561372181503\n",
      "SubGD iter. 308/499: loss=4.20195108012829, w0=73.30400000000004, w1=14.712378231823507\n",
      "SubGD iter. 309/499: loss=4.201993044395267, w0=73.30400000000004, w1=14.707772984834195\n",
      "SubGD iter. 310/499: loss=4.201962746824079, w0=73.30400000000004, w1=14.703167737844883\n",
      "SubGD iter. 311/499: loss=4.201937740909489, w0=73.31100000000005, w1=14.70409427285503\n",
      "SubGD iter. 312/499: loss=4.201956296199539, w0=73.30400000000004, w1=14.711911132497034\n",
      "SubGD iter. 313/499: loss=4.201989971384172, w0=73.30400000000004, w1=14.707305885507722\n",
      "SubGD iter. 314/499: loss=4.201959673812983, w0=73.30400000000004, w1=14.70270063851841\n",
      "SubGD iter. 315/499: loss=4.201938359172174, w0=73.31100000000005, w1=14.703627173528558\n",
      "SubGD iter. 316/499: loss=4.201961512270787, w0=73.30400000000004, w1=14.711444033170562\n",
      "SubGD iter. 317/499: loss=4.201986898373076, w0=73.30400000000004, w1=14.70683878618125\n",
      "SubGD iter. 318/499: loss=4.2019566008018865, w0=73.30400000000004, w1=14.702233539191937\n",
      "SubGD iter. 319/499: loss=4.201938977434859, w0=73.31100000000005, w1=14.703160074202085\n",
      "SubGD iter. 320/499: loss=4.201966728342036, w0=73.30400000000004, w1=14.710976933844089\n",
      "SubGD iter. 321/499: loss=4.201983825361981, w0=73.30400000000004, w1=14.706371686854776\n",
      "SubGD iter. 322/499: loss=4.201953527790791, w0=73.30400000000004, w1=14.701766439865464\n",
      "SubGD iter. 323/499: loss=4.201939595697542, w0=73.31100000000005, w1=14.702692974875612\n",
      "SubGD iter. 324/499: loss=4.201971944413285, w0=73.30400000000004, w1=14.710509834517616\n",
      "SubGD iter. 325/499: loss=4.2019807523508845, w0=73.30400000000004, w1=14.705904587528304\n",
      "SubGD iter. 326/499: loss=4.201950454779695, w0=73.30400000000004, w1=14.701299340538991\n",
      "SubGD iter. 327/499: loss=4.201940213960228, w0=73.31100000000005, w1=14.70222587554914\n",
      "SubGD iter. 328/499: loss=4.201977160484533, w0=73.30400000000004, w1=14.710042735191143\n",
      "SubGD iter. 329/499: loss=4.20197767933979, w0=73.30400000000004, w1=14.70543748820183\n",
      "SubGD iter. 330/499: loss=4.2019473817685995, w0=73.30400000000004, w1=14.700832241212519\n",
      "SubGD iter. 331/499: loss=4.201946471144322, w0=73.30400000000004, w1=14.714180882853983\n",
      "SubGD iter. 332/499: loss=4.2020049038998835, w0=73.30400000000004, w1=14.70957563586467\n",
      "SubGD iter. 333/499: loss=4.201974606328694, w0=73.30400000000004, w1=14.704970388875358\n",
      "SubGD iter. 334/499: loss=4.201944308757505, w0=73.30400000000004, w1=14.700365141886046\n",
      "SubGD iter. 335/499: loss=4.20195537848935, w0=73.30400000000004, w1=14.71371378352751\n",
      "SubGD iter. 336/499: loss=4.202001830888787, w0=73.30400000000004, w1=14.709108536538197\n",
      "SubGD iter. 337/499: loss=4.201971533317598, w0=73.30400000000004, w1=14.704503289548885\n",
      "SubGD iter. 338/499: loss=4.201941235746409, w0=73.30400000000004, w1=14.699898042559573\n",
      "SubGD iter. 339/499: loss=4.2019642858343795, w0=73.30400000000004, w1=14.713246684201037\n",
      "SubGD iter. 340/499: loss=4.201998757877692, w0=73.30400000000004, w1=14.708641437211725\n",
      "SubGD iter. 341/499: loss=4.201968460306502, w0=73.30400000000004, w1=14.704036190222412\n",
      "SubGD iter. 342/499: loss=4.201938162735313, w0=73.30400000000004, w1=14.6994309432331\n",
      "SubGD iter. 343/499: loss=4.201973193179408, w0=73.30400000000004, w1=14.712779584874564\n",
      "SubGD iter. 344/499: loss=4.201995684866596, w0=73.30400000000004, w1=14.708174337885252\n",
      "SubGD iter. 345/499: loss=4.201965387295407, w0=73.30400000000004, w1=14.70356909089594\n",
      "SubGD iter. 346/499: loss=4.201937209669985, w0=73.31100000000005, w1=14.704495625906087\n",
      "SubGD iter. 347/499: loss=4.201951814313157, w0=73.30400000000004, w1=14.712312485548091\n",
      "SubGD iter. 348/499: loss=4.201992611855501, w0=73.30400000000004, w1=14.707707238558779\n",
      "SubGD iter. 349/499: loss=4.201962314284311, w0=73.30400000000004, w1=14.703101991569467\n",
      "SubGD iter. 350/499: loss=4.201937827932668, w0=73.31100000000005, w1=14.704028526579615\n",
      "SubGD iter. 351/499: loss=4.201957030384405, w0=73.30400000000004, w1=14.711845386221619\n",
      "SubGD iter. 352/499: loss=4.201989538844405, w0=73.30400000000004, w1=14.707240139232306\n",
      "SubGD iter. 353/499: loss=4.201959241273216, w0=73.30400000000004, w1=14.702634892242994\n",
      "SubGD iter. 354/499: loss=4.201938446195354, w0=73.31100000000005, w1=14.703561427253142\n",
      "SubGD iter. 355/499: loss=4.201962246455654, w0=73.30400000000004, w1=14.711378286895146\n",
      "SubGD iter. 356/499: loss=4.2019864658333095, w0=73.30400000000004, w1=14.706773039905833\n",
      "SubGD iter. 357/499: loss=4.20195616826212, w0=73.30400000000004, w1=14.702167792916521\n",
      "SubGD iter. 358/499: loss=4.201939064458038, w0=73.31100000000005, w1=14.703094327926669\n",
      "SubGD iter. 359/499: loss=4.201967462526904, w0=73.30400000000004, w1=14.710911187568673\n",
      "SubGD iter. 360/499: loss=4.201983392822213, w0=73.30400000000004, w1=14.70630594057936\n",
      "SubGD iter. 361/499: loss=4.2019530952510245, w0=73.30400000000004, w1=14.701700693590048\n",
      "SubGD iter. 362/499: loss=4.201939682720723, w0=73.31100000000005, w1=14.702627228600196\n",
      "SubGD iter. 363/499: loss=4.2019726785981515, w0=73.30400000000004, w1=14.7104440882422\n",
      "SubGD iter. 364/499: loss=4.201980319811118, w0=73.30400000000004, w1=14.705838841252888\n",
      "SubGD iter. 365/499: loss=4.201950022239929, w0=73.30400000000004, w1=14.701233594263575\n",
      "SubGD iter. 366/499: loss=4.2019403009834075, w0=73.31100000000005, w1=14.702160129273723\n",
      "SubGD iter. 367/499: loss=4.201977894669399, w0=73.30400000000004, w1=14.709976988915727\n",
      "SubGD iter. 368/499: loss=4.2019772468000225, w0=73.30400000000004, w1=14.705371741926415\n",
      "SubGD iter. 369/499: loss=4.201946949228833, w0=73.30400000000004, w1=14.700766494937103\n",
      "SubGD iter. 370/499: loss=4.201947724892135, w0=73.30400000000004, w1=14.714115136578567\n",
      "SubGD iter. 371/499: loss=4.202004471360116, w0=73.30400000000004, w1=14.709509889589254\n",
      "SubGD iter. 372/499: loss=4.201974173788926, w0=73.30400000000004, w1=14.704904642599942\n",
      "SubGD iter. 373/499: loss=4.2019438762177375, w0=73.30400000000004, w1=14.70029939561063\n",
      "SubGD iter. 374/499: loss=4.201956632237165, w0=73.30400000000004, w1=14.713648037252094\n",
      "SubGD iter. 375/499: loss=4.2020013983490205, w0=73.30400000000004, w1=14.709042790262782\n",
      "SubGD iter. 376/499: loss=4.201971100777831, w0=73.30400000000004, w1=14.70443754327347\n",
      "SubGD iter. 377/499: loss=4.201940803206642, w0=73.30400000000004, w1=14.699832296284157\n",
      "SubGD iter. 378/499: loss=4.201965539582193, w0=73.30400000000004, w1=14.713180937925621\n",
      "SubGD iter. 379/499: loss=4.201998325337925, w0=73.30400000000004, w1=14.708575690936309\n",
      "SubGD iter. 380/499: loss=4.2019680277667355, w0=73.30400000000004, w1=14.703970443946996\n",
      "SubGD iter. 381/499: loss=4.201937730195546, w0=73.30400000000004, w1=14.699365196957684\n",
      "SubGD iter. 382/499: loss=4.201974446927222, w0=73.30400000000004, w1=14.712713838599148\n",
      "SubGD iter. 383/499: loss=4.20199525232683, w0=73.30400000000004, w1=14.708108591609836\n",
      "SubGD iter. 384/499: loss=4.20196495475564, w0=73.30400000000004, w1=14.703503344620524\n",
      "SubGD iter. 385/499: loss=4.201937296693164, w0=73.31100000000005, w1=14.704429879630672\n",
      "SubGD iter. 386/499: loss=4.201952548498024, w0=73.30400000000004, w1=14.712246739272675\n",
      "SubGD iter. 387/499: loss=4.2019921793157335, w0=73.30400000000004, w1=14.707641492283363\n",
      "SubGD iter. 388/499: loss=4.201961881744544, w0=73.30400000000004, w1=14.70303624529405\n",
      "SubGD iter. 389/499: loss=4.201937914955849, w0=73.31100000000005, w1=14.703962780304199\n",
      "SubGD iter. 390/499: loss=4.201957764569273, w0=73.30400000000004, w1=14.711779639946203\n",
      "SubGD iter. 391/499: loss=4.201989106304638, w0=73.30400000000004, w1=14.70717439295689\n",
      "SubGD iter. 392/499: loss=4.2019588087334485, w0=73.30400000000004, w1=14.702569145967578\n",
      "SubGD iter. 393/499: loss=4.2019385332185335, w0=73.31100000000005, w1=14.703495680977726\n",
      "SubGD iter. 394/499: loss=4.201962980640522, w0=73.30400000000004, w1=14.71131254061973\n",
      "SubGD iter. 395/499: loss=4.201986033293542, w0=73.30400000000004, w1=14.706707293630418\n",
      "SubGD iter. 396/499: loss=4.201955735722353, w0=73.30400000000004, w1=14.702102046641105\n",
      "SubGD iter. 397/499: loss=4.201939151481218, w0=73.31100000000005, w1=14.703028581651253\n",
      "SubGD iter. 398/499: loss=4.2019681967117695, w0=73.30400000000004, w1=14.710845441293257\n",
      "SubGD iter. 399/499: loss=4.2019829602824466, w0=73.30400000000004, w1=14.706240194303945\n",
      "SubGD iter. 400/499: loss=4.201952662711257, w0=73.30400000000004, w1=14.701634947314632\n",
      "SubGD iter. 401/499: loss=4.201939769743903, w0=73.31100000000005, w1=14.70256148232478\n",
      "SubGD iter. 402/499: loss=4.201973412783018, w0=73.30400000000004, w1=14.710378341966784\n",
      "SubGD iter. 403/499: loss=4.201979887271351, w0=73.30400000000004, w1=14.705773094977472\n",
      "SubGD iter. 404/499: loss=4.201949589700161, w0=73.30400000000004, w1=14.70116784798816\n",
      "SubGD iter. 405/499: loss=4.201940388006587, w0=73.31100000000005, w1=14.702094382998308\n",
      "SubGD iter. 406/499: loss=4.201978628854267, w0=73.30400000000004, w1=14.709911242640311\n",
      "SubGD iter. 407/499: loss=4.201976814260256, w0=73.30400000000004, w1=14.705305995650999\n",
      "SubGD iter. 408/499: loss=4.201946516689066, w0=73.30400000000004, w1=14.700700748661687\n",
      "SubGD iter. 409/499: loss=4.20194897863995, w0=73.30400000000004, w1=14.71404939030315\n",
      "SubGD iter. 410/499: loss=4.202004038820349, w0=73.30400000000004, w1=14.709444143313839\n",
      "SubGD iter. 411/499: loss=4.20197374124916, w0=73.30400000000004, w1=14.704838896324526\n",
      "SubGD iter. 412/499: loss=4.201943443677971, w0=73.30400000000004, w1=14.700233649335214\n",
      "SubGD iter. 413/499: loss=4.201957885984979, w0=73.30400000000004, w1=14.713582290976678\n",
      "SubGD iter. 414/499: loss=4.202000965809253, w0=73.30400000000004, w1=14.708977043987366\n",
      "SubGD iter. 415/499: loss=4.201970668238064, w0=73.30400000000004, w1=14.704371796998053\n",
      "SubGD iter. 416/499: loss=4.2019403706668745, w0=73.30400000000004, w1=14.699766550008741\n",
      "SubGD iter. 417/499: loss=4.201966793330007, w0=73.30400000000004, w1=14.713115191650205\n",
      "SubGD iter. 418/499: loss=4.2019978927981585, w0=73.30400000000004, w1=14.708509944660893\n",
      "SubGD iter. 419/499: loss=4.201967595226969, w0=73.30400000000004, w1=14.70390469767158\n",
      "SubGD iter. 420/499: loss=4.201937297655779, w0=73.30400000000004, w1=14.699299450682268\n",
      "SubGD iter. 421/499: loss=4.201975700675035, w0=73.30400000000004, w1=14.712648092323732\n",
      "SubGD iter. 422/499: loss=4.201994819787062, w0=73.30400000000004, w1=14.70804284533442\n",
      "SubGD iter. 423/499: loss=4.201964522215873, w0=73.30400000000004, w1=14.703437598345108\n",
      "SubGD iter. 424/499: loss=4.201937383716345, w0=73.31100000000005, w1=14.704364133355256\n",
      "SubGD iter. 425/499: loss=4.201953282682891, w0=73.30400000000004, w1=14.71218099299726\n",
      "SubGD iter. 426/499: loss=4.201991746775966, w0=73.30400000000004, w1=14.707575746007947\n",
      "SubGD iter. 427/499: loss=4.201961449204777, w0=73.30400000000004, w1=14.702970499018635\n",
      "SubGD iter. 428/499: loss=4.201938001979029, w0=73.31100000000005, w1=14.703897034028783\n",
      "SubGD iter. 429/499: loss=4.20195849875414, w0=73.30400000000004, w1=14.711713893670787\n",
      "SubGD iter. 430/499: loss=4.201988673764871, w0=73.30400000000004, w1=14.707108646681474\n",
      "SubGD iter. 431/499: loss=4.201958376193682, w0=73.30400000000004, w1=14.702503399692162\n",
      "SubGD iter. 432/499: loss=4.201938620241714, w0=73.31100000000005, w1=14.70342993470231\n",
      "SubGD iter. 433/499: loss=4.201963714825389, w0=73.30400000000004, w1=14.711246794344314\n",
      "SubGD iter. 434/499: loss=4.201985600753775, w0=73.30400000000004, w1=14.706641547355002\n",
      "SubGD iter. 435/499: loss=4.2019553031825865, w0=73.30400000000004, w1=14.70203630036569\n",
      "SubGD iter. 436/499: loss=4.201939238504399, w0=73.31100000000005, w1=14.702962835375837\n",
      "SubGD iter. 437/499: loss=4.201968930896637, w0=73.30400000000004, w1=14.710779695017841\n",
      "SubGD iter. 438/499: loss=4.201982527742679, w0=73.30400000000004, w1=14.706174448028529\n",
      "SubGD iter. 439/499: loss=4.20195223017149, w0=73.30400000000004, w1=14.701569201039216\n",
      "SubGD iter. 440/499: loss=4.2019398567670825, w0=73.31100000000005, w1=14.702495736049364\n",
      "SubGD iter. 441/499: loss=4.201974146967885, w0=73.30400000000004, w1=14.710312595691368\n",
      "SubGD iter. 442/499: loss=4.201979454731584, w0=73.30400000000004, w1=14.705707348702056\n",
      "SubGD iter. 443/499: loss=4.201949157160395, w0=73.30400000000004, w1=14.701102101712744\n",
      "SubGD iter. 444/499: loss=4.2019413250427355, w0=73.30400000000004, w1=14.714450743354208\n",
      "SubGD iter. 445/499: loss=4.202006679291678, w0=73.30400000000004, w1=14.709845496364895\n",
      "SubGD iter. 446/499: loss=4.201976381720488, w0=73.30400000000004, w1=14.705240249375583\n",
      "SubGD iter. 447/499: loss=4.201946084149299, w0=73.30400000000004, w1=14.70063500238627\n",
      "SubGD iter. 448/499: loss=4.201950232387764, w0=73.30400000000004, w1=14.713983644027735\n",
      "SubGD iter. 449/499: loss=4.202003606280582, w0=73.30400000000004, w1=14.709378397038423\n",
      "SubGD iter. 450/499: loss=4.201973308709393, w0=73.30400000000004, w1=14.70477315004911\n",
      "SubGD iter. 451/499: loss=4.201943011138204, w0=73.30400000000004, w1=14.700167903059798\n",
      "SubGD iter. 452/499: loss=4.201959139732792, w0=73.30400000000004, w1=14.713516544701262\n",
      "SubGD iter. 453/499: loss=4.202000533269486, w0=73.30400000000004, w1=14.70891129771195\n",
      "SubGD iter. 454/499: loss=4.2019702356982975, w0=73.30400000000004, w1=14.704306050722638\n",
      "SubGD iter. 455/499: loss=4.201939938127108, w0=73.30400000000004, w1=14.699700803733325\n",
      "SubGD iter. 456/499: loss=4.201968047077822, w0=73.30400000000004, w1=14.71304944537479\n",
      "SubGD iter. 457/499: loss=4.201997460258391, w0=73.30400000000004, w1=14.708444198385477\n",
      "SubGD iter. 458/499: loss=4.201967162687201, w0=73.30400000000004, w1=14.703838951396165\n",
      "SubGD iter. 459/499: loss=4.2019368651160125, w0=73.30400000000004, w1=14.699233704406852\n",
      "SubGD iter. 460/499: loss=4.201976954422849, w0=73.30400000000004, w1=14.712582346048316\n",
      "SubGD iter. 461/499: loss=4.201994387247296, w0=73.30400000000004, w1=14.707977099059004\n",
      "SubGD iter. 462/499: loss=4.201964089676105, w0=73.30400000000004, w1=14.703371852069692\n",
      "SubGD iter. 463/499: loss=4.201937470739525, w0=73.31100000000005, w1=14.70429838707984\n",
      "SubGD iter. 464/499: loss=4.2019540168677585, w0=73.30400000000004, w1=14.712115246721844\n",
      "SubGD iter. 465/499: loss=4.201991314236199, w0=73.30400000000004, w1=14.707509999732531\n",
      "SubGD iter. 466/499: loss=4.20196101666501, w0=73.30400000000004, w1=14.702904752743219\n",
      "SubGD iter. 467/499: loss=4.201938089002209, w0=73.31100000000005, w1=14.703831287753367\n",
      "SubGD iter. 468/499: loss=4.201959232939007, w0=73.30400000000004, w1=14.71164814739537\n",
      "SubGD iter. 469/499: loss=4.201988241225104, w0=73.30400000000004, w1=14.707042900406059\n",
      "SubGD iter. 470/499: loss=4.201957943653915, w0=73.30400000000004, w1=14.702437653416746\n",
      "SubGD iter. 471/499: loss=4.201938707264894, w0=73.31100000000005, w1=14.703364188426894\n",
      "SubGD iter. 472/499: loss=4.201964449010255, w0=73.30400000000004, w1=14.711181048068898\n",
      "SubGD iter. 473/499: loss=4.201985168214009, w0=73.30400000000004, w1=14.706575801079586\n",
      "SubGD iter. 474/499: loss=4.201954870642819, w0=73.30400000000004, w1=14.701970554090273\n",
      "SubGD iter. 475/499: loss=4.2019393255275785, w0=73.31100000000005, w1=14.702897089100421\n",
      "SubGD iter. 476/499: loss=4.201969665081504, w0=73.30400000000004, w1=14.710713948742425\n",
      "SubGD iter. 477/499: loss=4.201982095202912, w0=73.30400000000004, w1=14.706108701753113\n",
      "SubGD iter. 478/499: loss=4.2019517976317236, w0=73.30400000000004, w1=14.7015034547638\n",
      "SubGD iter. 479/499: loss=4.201939943790263, w0=73.31100000000005, w1=14.702429989773949\n",
      "SubGD iter. 480/499: loss=4.2019748811527515, w0=73.30400000000004, w1=14.710246849415952\n",
      "SubGD iter. 481/499: loss=4.201979022191818, w0=73.30400000000004, w1=14.70564160242664\n",
      "SubGD iter. 482/499: loss=4.201948724620628, w0=73.30400000000004, w1=14.701036355437328\n",
      "SubGD iter. 483/499: loss=4.2019425787905496, w0=73.30400000000004, w1=14.714384997078792\n",
      "SubGD iter. 484/499: loss=4.20200624675191, w0=73.30400000000004, w1=14.70977975008948\n",
      "SubGD iter. 485/499: loss=4.201975949180722, w0=73.30400000000004, w1=14.705174503100167\n",
      "SubGD iter. 486/499: loss=4.201945651609532, w0=73.30400000000004, w1=14.700569256110855\n",
      "SubGD iter. 487/499: loss=4.201951486135577, w0=73.30400000000004, w1=14.713917897752319\n",
      "SubGD iter. 488/499: loss=4.202003173740815, w0=73.30400000000004, w1=14.709312650763007\n",
      "SubGD iter. 489/499: loss=4.201972876169625, w0=73.30400000000004, w1=14.704707403773694\n",
      "SubGD iter. 490/499: loss=4.201942578598437, w0=73.30400000000004, w1=14.700102156784382\n",
      "SubGD iter. 491/499: loss=4.201960393480606, w0=73.30400000000004, w1=14.713450798425846\n",
      "SubGD iter. 492/499: loss=4.20200010072972, w0=73.30400000000004, w1=14.708845551436534\n",
      "SubGD iter. 493/499: loss=4.20196980315853, w0=73.30400000000004, w1=14.704240304447222\n",
      "SubGD iter. 494/499: loss=4.20193950558734, w0=73.30400000000004, w1=14.69963505745791\n",
      "SubGD iter. 495/499: loss=4.201969300825636, w0=73.30400000000004, w1=14.712983699099373\n",
      "SubGD iter. 496/499: loss=4.201997027718624, w0=73.30400000000004, w1=14.708378452110061\n",
      "SubGD iter. 497/499: loss=4.201966730147434, w0=73.30400000000004, w1=14.703773205120749\n",
      "SubGD iter. 498/499: loss=4.20193693950002, w0=73.31100000000005, w1=14.704699740130897\n",
      "SubGD iter. 499/499: loss=4.201949534981377, w0=73.30400000000004, w1=14.7125165997729\n",
      "SubGD: execution time=0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453a90e3c8db4eb7a9482a87e12334f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        raise NotImplementedError\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
