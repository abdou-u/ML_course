{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FMIviIzeH9Pm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable as V\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcyQiG6Rn7qw",
        "outputId": "62d6067c-568d-41a1-c76e-399f6e976a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cV884hneIj75"
      },
      "outputs": [],
      "source": [
        "class dice_bce_loss(nn.Module):\n",
        "    def __init__(self, batch=True):\n",
        "        super(dice_bce_loss, self).__init__()\n",
        "        self.batch = batch\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def soft_dice_coeff(self, y_true, y_pred):\n",
        "        smooth = 0.0  # may change\n",
        "        if self.batch:\n",
        "            i = torch.sum(y_true)\n",
        "            j = torch.sum(y_pred)\n",
        "            intersection = torch.sum(y_true * y_pred)\n",
        "        else:\n",
        "            i = y_true.sum(1).sum(1).sum(1)\n",
        "            j = y_pred.sum(1).sum(1).sum(1)\n",
        "            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n",
        "        score = (2. * intersection + smooth) / (i + j + smooth)\n",
        "        return score.mean()\n",
        "\n",
        "    def soft_dice_loss(self, y_true, y_pred):\n",
        "        loss = 1 - self.soft_dice_coeff(y_true, y_pred)\n",
        "        return loss\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        a =  self.bce_loss(y_pred, y_true)\n",
        "        b =  self.soft_dice_loss(y_true, y_pred)\n",
        "        return a + b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QEByGEmz67vn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "\n",
        "nonlinearity = partial(F.relu, inplace=True)\n",
        "\n",
        "\n",
        "#CBAMæ”¹\n",
        "\n",
        "class Channel(nn.Module ):\n",
        "    def __init__(self,inchannel,reduction=16):\n",
        "        super(Channel, self).__init__()\n",
        "        radio=reduction //2\n",
        "\n",
        "\n",
        "        self.gap=nn.AdaptiveAvgPool2d(1)\n",
        "        self.gmp=nn.AdaptiveMaxPool2d (1)\n",
        "\n",
        "        self.mlp=nn.Sequential (\n",
        "            nn.Conv2d(inchannel ,inchannel //radio ,1,1,0,bias= False ),\n",
        "            nn.ReLU (),\n",
        "            nn.Conv2d (inchannel //radio,inchannel//reduction ,1,1,0,bias= False ),\n",
        "            nn.ReLU (),\n",
        "            nn.Conv2d (inchannel //reduction ,inchannel//radio ,1,1,0,bias= False ),\n",
        "            nn.ReLU (),\n",
        "            nn.Conv2d (inchannel//radio,inchannel ,1,1,0,bias= False )\n",
        "        )\n",
        "        self.sig=nn.Sigmoid ()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        gap=self.gap (x)\n",
        "        gmp=self.gmp(x)\n",
        "\n",
        "        gap=self.mlp(gap)\n",
        "        gmp=self.mlp(gmp)\n",
        "\n",
        "\n",
        "        return self.sig(gap+gmp)\n",
        "\n",
        "\n",
        "class Spatial(nn.Module ):\n",
        "    def __init__(self):\n",
        "        super(Spatial, self).__init__()\n",
        "\n",
        "        self.conv=nn.Sequential (\n",
        "\n",
        "            nn.Conv2d (in_channels= 2,out_channels= 2,kernel_size= 3,stride= 1,padding= 1,bias= False ),\n",
        "            nn.ReLU (),\n",
        "            nn.Conv2d (in_channels= 2,out_channels= 2,kernel_size= 3,stride= 1,padding= 1,bias= False ),\n",
        "            nn.ReLU (),\n",
        "            nn.Conv2d (in_channels= 2,out_channels= 1,kernel_size= 3,stride= 1,padding= 1,bias= False )\n",
        "        )\n",
        "\n",
        "        self.sig=nn.Sigmoid ()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        max_pool,_=torch.max (x,dim=1,keepdim= True)\n",
        "        avg_pool  =torch.mean(x,dim=1,keepdim= True)\n",
        "\n",
        "        cc=torch.cat([max_pool ,avg_pool ],dim= 1)\n",
        "\n",
        "        cc=self.conv (cc)\n",
        "\n",
        "        cc=self.sig(cc)\n",
        "\n",
        "        return cc\n",
        "\n",
        "\n",
        "class CBAMs(nn.Module ):\n",
        "    def __init__(self,inchannel,reduction):\n",
        "        super(CBAMs, self).__init__()\n",
        "\n",
        "        self.channel=Channel (inchannel ,reduction )\n",
        "        self.spatial=Spatial ()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        ca=self.channel (x)\n",
        "        out=ca*x\n",
        "        sa=self.spatial (out)\n",
        "        out=out*sa\n",
        "\n",
        "        return out\n",
        "\n",
        "class Dblock(nn.Module):\n",
        "    def __init__(self, channel,d_bin):\n",
        "        super(Dblock, self).__init__()\n",
        "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=3, dilation=d_bin[0], padding=d_bin[0])\n",
        "        self.dilate2 = nn.Conv2d(channel, channel, kernel_size=3, dilation=d_bin[1], padding=d_bin[1])\n",
        "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=d_bin[2], padding=d_bin[2])\n",
        "        self.dilate4 = nn.Conv2d(channel, channel, kernel_size=3, dilation=d_bin[3], padding=d_bin[3])\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "        self.att=CBAMs(channel,16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        dilate1_out = nonlinearity(self.dilate1(x))\n",
        "        dilate2_out = nonlinearity(self.dilate2(dilate1_out))\n",
        "        dilate3_out = nonlinearity(self.dilate3(dilate2_out))\n",
        "        dilate4_out = nonlinearity(self.dilate4(dilate3_out))\n",
        "\n",
        "        out = x + dilate1_out + dilate2_out + dilate3_out + dilate4_out\n",
        "        return self.att(out)\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, n_filters):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
        "        self.relu1 = nonlinearity\n",
        "\n",
        "        self.deconv2 = nn.ConvTranspose2d(in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1)\n",
        "        self.norm2 = nn.BatchNorm2d(in_channels // 4)\n",
        "        self.relu2 = nonlinearity\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
        "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
        "        self.relu3 = nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "class RFE_LINKNET(nn.Module):\n",
        "    def __init__(self, num_classes=1, num_channels=3):\n",
        "        super(RFE_LINKNET, self).__init__()\n",
        "\n",
        "        filters = [64, 128, 256, 512]\n",
        "        resnet = models.resnet34(pretrained=True)\n",
        "        self.firstconv = resnet.conv1\n",
        "        self.firstbn = resnet.bn1\n",
        "        self.firstrelu = resnet.relu\n",
        "        self.firstmaxpool = resnet.maxpool\n",
        "        self.encoder1 = resnet.layer1\n",
        "        self.encoder2 = resnet.layer2\n",
        "        self.encoder3 = resnet.layer3\n",
        "        self.encoder4 = resnet.layer4\n",
        "\n",
        "        self.dblock1=Dblock(64,d_bin=[1,32,32,64])\n",
        "        self.dblock2=Dblock(128,d_bin=[1,16,16,32])\n",
        "        self.dblock3=Dblock(256,d_bin=[1,4,8,16])\n",
        "        self.dblock4=Dblock(512,d_bin=[1,2,4,8])\n",
        "\n",
        "\n",
        "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
        "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
        "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
        "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
        "\n",
        "\n",
        "\n",
        "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
        "        self.finalrelu1 = nonlinearity\n",
        "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.finalrelu2 = nonlinearity\n",
        "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.firstconv(x)\n",
        "        x = self.firstbn(x)\n",
        "        x = self.firstrelu(x)\n",
        "        x = self.firstmaxpool(x)\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "\n",
        "        # Center\n",
        "\n",
        "        e4=self.dblock4(e4)\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.decoder4(e4)+self.dblock3(e3)\n",
        "        d3 = self.decoder3(d4)+self.dblock2(e2)\n",
        "        d2 = self.decoder2(d3)+self.dblock1(e1)\n",
        "        d1 = self.decoder1(d2)\n",
        "\n",
        "        out = self.finaldeconv1(d1)\n",
        "        out = self.finalrelu1(out)\n",
        "        out = self.finalconv2(out)\n",
        "        out = self.finalrelu2(out)\n",
        "        out = self.finalconv3(out)\n",
        "\n",
        "        return F.sigmoid(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp9kPfGYLsOS",
        "outputId": "ee87178d-27d3-4f21-b5be-9db1725471e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b9d4b125d7fc>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('rfelinknet.pth')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model = RFE_LINKNET(num_classes=1, num_channels=3)  # Adjust parameters if necessary\n",
        "model.cuda()\n",
        "checkpoint = torch.load('rfelinknet.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXkQZUm0UAJb",
        "outputId": "4424ab23-16f2-4348-86c8-0509a67fc4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/ML_P2_QuantumMinds/test.zip\n",
            "   creating: data/test/\n",
            "   creating: data/test/test_set_images/\n",
            "   creating: data/test/test_set_images/test_1/\n",
            "  inflating: data/test/test_set_images/test_1/test_1.png  \n",
            "   creating: data/test/test_set_images/test_10/\n",
            "  inflating: data/test/test_set_images/test_10/test_10.png  \n",
            "   creating: data/test/test_set_images/test_11/\n",
            "  inflating: data/test/test_set_images/test_11/test_11.png  \n",
            "   creating: data/test/test_set_images/test_12/\n",
            "  inflating: data/test/test_set_images/test_12/test_12.png  \n",
            "   creating: data/test/test_set_images/test_13/\n",
            "  inflating: data/test/test_set_images/test_13/test_13.png  \n",
            "   creating: data/test/test_set_images/test_14/\n",
            "  inflating: data/test/test_set_images/test_14/test_14.png  \n",
            "   creating: data/test/test_set_images/test_15/\n",
            "  inflating: data/test/test_set_images/test_15/test_15.png  \n",
            "   creating: data/test/test_set_images/test_16/\n",
            "  inflating: data/test/test_set_images/test_16/test_16.png  \n",
            "   creating: data/test/test_set_images/test_17/\n",
            "  inflating: data/test/test_set_images/test_17/test_17.png  \n",
            "   creating: data/test/test_set_images/test_18/\n",
            "  inflating: data/test/test_set_images/test_18/test_18.png  \n",
            "   creating: data/test/test_set_images/test_19/\n",
            "  inflating: data/test/test_set_images/test_19/test_19.png  \n",
            "   creating: data/test/test_set_images/test_2/\n",
            "  inflating: data/test/test_set_images/test_2/test_2.png  \n",
            "   creating: data/test/test_set_images/test_20/\n",
            "  inflating: data/test/test_set_images/test_20/test_20.png  \n",
            "   creating: data/test/test_set_images/test_21/\n",
            "  inflating: data/test/test_set_images/test_21/test_21.png  \n",
            "   creating: data/test/test_set_images/test_22/\n",
            "  inflating: data/test/test_set_images/test_22/test_22.png  \n",
            "   creating: data/test/test_set_images/test_23/\n",
            "  inflating: data/test/test_set_images/test_23/test_23.png  \n",
            "   creating: data/test/test_set_images/test_24/\n",
            "  inflating: data/test/test_set_images/test_24/test_24.png  \n",
            "   creating: data/test/test_set_images/test_25/\n",
            "  inflating: data/test/test_set_images/test_25/test_25.png  \n",
            "   creating: data/test/test_set_images/test_26/\n",
            "  inflating: data/test/test_set_images/test_26/test_26.png  \n",
            "   creating: data/test/test_set_images/test_27/\n",
            "  inflating: data/test/test_set_images/test_27/test_27.png  \n",
            "   creating: data/test/test_set_images/test_28/\n",
            "  inflating: data/test/test_set_images/test_28/test_28.png  \n",
            "   creating: data/test/test_set_images/test_29/\n",
            "  inflating: data/test/test_set_images/test_29/test_29.png  \n",
            "   creating: data/test/test_set_images/test_3/\n",
            "  inflating: data/test/test_set_images/test_3/test_3.png  \n",
            "   creating: data/test/test_set_images/test_30/\n",
            "  inflating: data/test/test_set_images/test_30/test_30.png  \n",
            "   creating: data/test/test_set_images/test_31/\n",
            "  inflating: data/test/test_set_images/test_31/test_31.png  \n",
            "   creating: data/test/test_set_images/test_32/\n",
            "  inflating: data/test/test_set_images/test_32/test_32.png  \n",
            "   creating: data/test/test_set_images/test_33/\n",
            "  inflating: data/test/test_set_images/test_33/test_33.png  \n",
            "   creating: data/test/test_set_images/test_34/\n",
            "  inflating: data/test/test_set_images/test_34/test_34.png  \n",
            "   creating: data/test/test_set_images/test_35/\n",
            "  inflating: data/test/test_set_images/test_35/test_35.png  \n",
            "   creating: data/test/test_set_images/test_36/\n",
            "  inflating: data/test/test_set_images/test_36/test_36.png  \n",
            "   creating: data/test/test_set_images/test_37/\n",
            "  inflating: data/test/test_set_images/test_37/test_37.png  \n",
            "   creating: data/test/test_set_images/test_38/\n",
            "  inflating: data/test/test_set_images/test_38/test_38.png  \n",
            "   creating: data/test/test_set_images/test_39/\n",
            "  inflating: data/test/test_set_images/test_39/test_39.png  \n",
            "   creating: data/test/test_set_images/test_4/\n",
            "  inflating: data/test/test_set_images/test_4/test_4.png  \n",
            "   creating: data/test/test_set_images/test_40/\n",
            "  inflating: data/test/test_set_images/test_40/test_40.png  \n",
            "   creating: data/test/test_set_images/test_41/\n",
            "  inflating: data/test/test_set_images/test_41/test_41.png  \n",
            "   creating: data/test/test_set_images/test_42/\n",
            "  inflating: data/test/test_set_images/test_42/test_42.png  \n",
            "   creating: data/test/test_set_images/test_43/\n",
            "  inflating: data/test/test_set_images/test_43/test_43.png  \n",
            "   creating: data/test/test_set_images/test_44/\n",
            "  inflating: data/test/test_set_images/test_44/test_44.png  \n",
            "   creating: data/test/test_set_images/test_45/\n",
            "  inflating: data/test/test_set_images/test_45/test_45.png  \n",
            "   creating: data/test/test_set_images/test_46/\n",
            "  inflating: data/test/test_set_images/test_46/test_46.png  \n",
            "   creating: data/test/test_set_images/test_47/\n",
            "  inflating: data/test/test_set_images/test_47/test_47.png  \n",
            "   creating: data/test/test_set_images/test_48/\n",
            "  inflating: data/test/test_set_images/test_48/test_48.png  \n",
            "   creating: data/test/test_set_images/test_49/\n",
            "  inflating: data/test/test_set_images/test_49/test_49.png  \n",
            "   creating: data/test/test_set_images/test_5/\n",
            "  inflating: data/test/test_set_images/test_5/test_5.png  \n",
            "   creating: data/test/test_set_images/test_50/\n",
            "  inflating: data/test/test_set_images/test_50/test_50.png  \n",
            "   creating: data/test/test_set_images/test_6/\n",
            "  inflating: data/test/test_set_images/test_6/test_6.png  \n",
            "   creating: data/test/test_set_images/test_7/\n",
            "  inflating: data/test/test_set_images/test_7/test_7.png  \n",
            "   creating: data/test/test_set_images/test_8/\n",
            "  inflating: data/test/test_set_images/test_8/test_8.png  \n",
            "   creating: data/test/test_set_images/test_9/\n",
            "  inflating: data/test/test_set_images/test_9/test_9.png  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/ML_P2_QuantumMinds/test.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiq2QJeuNXEi",
        "outputId": "816904ed-3dbd-40e8-cc6b-166d28b9043d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 14.08it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_patches(input_image, patch_size=384):\n",
        "    \"\"\"\n",
        "    Extracts 4 non-overlapping patches from a 608x608 input image.\n",
        "    \"\"\"\n",
        "    patches = np.empty((4, input_image.shape[2], patch_size, patch_size))\n",
        "    offsets = [(0, 0), (0, 224), (224, 0), (224, 224)]\n",
        "\n",
        "    for i, (y, x) in enumerate(offsets):\n",
        "        patches[i] = np.transpose(input_image[y:y+patch_size, x:x+patch_size, :], (2, 0, 1))\n",
        "\n",
        "    return patches\n",
        "\n",
        "def assemble_patches(patches):\n",
        "    \"\"\"\n",
        "    Assembles 4 patches back into a 608x608 output.\n",
        "    \"\"\"\n",
        "    output = np.empty((patches.shape[1], 608, 608))\n",
        "    offsets = [(0, 0), (0, 224), (224, 0), (224, 224)]\n",
        "\n",
        "    for i, (y, x) in enumerate(offsets):\n",
        "        output[:, y:y+384, x:x+384] = patches[i]\n",
        "\n",
        "    return output\n",
        "\n",
        "def mask_to_submission_format(mask, index):\n",
        "    \"\"\"\n",
        "    Converts a mask into the submission format.\n",
        "    \"\"\"\n",
        "    submission = []\n",
        "    for y in range(0, mask.shape[0], 16):\n",
        "        for x in range(0, mask.shape[1], 16):\n",
        "            patch = mask[y:y+16, x:x+16]\n",
        "            prediction = 1 if np.mean(patch > 0.2) > 0.25 else 0\n",
        "            submission.append([f\"{index:03d}_{x}_{y}\", prediction])\n",
        "    return submission\n",
        "\n",
        "def create_submission(model, test_images_path='test_set_images/', patch_size=384, cuda=True):\n",
        "    \"\"\"\n",
        "    Generates a submission file by predicting masks for the test set images.\n",
        "    \"\"\"\n",
        "    all_submissions = []\n",
        "\n",
        "    for index in tqdm(range(1, 51)):\n",
        "        model.eval()\n",
        "\n",
        "        # Load and preprocess the test image\n",
        "        input_image = np.array(Image.open(f'{test_images_path}/test_{index}/test_{index}.png')).astype('float32') / 255\n",
        "        input_patches = extract_patches(input_image)\n",
        "        input_patches = torch.from_numpy(input_patches).float()\n",
        "\n",
        "        # Perform inference\n",
        "        if cuda:\n",
        "            predictions = model(input_patches.cuda()).detach().cpu().numpy()\n",
        "        else:\n",
        "            predictions = model(input_patches).detach().numpy()\n",
        "\n",
        "        # Assemble patches into a full mask\n",
        "        output_mask = assemble_patches(predictions)[0]\n",
        "\n",
        "        if index==19:\n",
        "            # Save the input image and output mask for index 19\n",
        "            #input_image_path = os.path.join('', f'input_image_{index}.png')\n",
        "            output_mask_path = os.path.join('', f'rfe-linknet_test{index}.png')\n",
        "\n",
        "            # Save input image and output mask\n",
        "            #Image.fromarray((input_image * 255).astype(np.uint8)).save(input_image_path)\n",
        "            Image.fromarray((output_mask * 255).astype(np.uint8)).save(output_mask_path)\n",
        "\n",
        "\n",
        "        # Convert mask to submission format\n",
        "        submission = mask_to_submission_format(output_mask, index)\n",
        "        all_submissions.extend(submission)\n",
        "\n",
        "    # Add header to submission\n",
        "    submission = [['id', 'prediction']] + all_submissions\n",
        "    return np.array(submission)\n",
        "\n",
        "# Example usage\n",
        "submission = create_submission(model, 'data/test/test_set_images', 384, True)\n",
        "np.savetxt(\"submit.csv\", submission, delimiter=\",\", fmt='%s')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}